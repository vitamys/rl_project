{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from simglucose.envs import T1DSimEnv\n",
    "import gym\n",
    "from gym.envs.registration import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SETUP LOGGER\n",
    "###################\n",
    "\n",
    "import logging\n",
    "\n",
    "# create logger\n",
    "logger = logging.getLogger(__name__)\n",
    "# set log level for all handlers to debug\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "# best for development or debugging\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# add formatter to ch\n",
    "consoleHandler.setFormatter(formatter)\n",
    "\n",
    "# add ch to logger\n",
    "logger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 12:25:10,837 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:25:10,840 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:25:10,842 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:25:10,844 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:25:10,846 - __main__ - INFO - Creating new one day scenario ...\n",
      "2023-12-21 12:25:10,846 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:25:10,846 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:25:10,846 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:25:10,846 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:25:10,863 - __main__ - INFO - Creating new one day scenario ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from simglucose.simulation.scenario import Action, Scenario\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "#logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class RandomScenario(Scenario):\n",
    "    def __init__(self, start_time, seed=None):\n",
    "        Scenario.__init__(self, start_time=start_time)\n",
    "        self.seed = seed\n",
    "\n",
    "    def get_action(self, t):\n",
    "        # t must be datetime.datetime object\n",
    "        delta_t = t - datetime.combine(t.date(), datetime.min.time())\n",
    "        t_sec = delta_t.total_seconds()\n",
    "\n",
    "        if t_sec < 1:\n",
    "            logger.info('Creating new one day scenario ...')\n",
    "            self.scenario = self.create_scenario()\n",
    "\n",
    "        t_min = np.floor(t_sec / 60.0)\n",
    "\n",
    "        if t_min in self.scenario['meal']['time']:\n",
    "            logger.info('Time for meal!')\n",
    "            idx = self.scenario['meal']['time'].index(t_min)\n",
    "            return Action(meal=self.scenario['meal']['amount'][idx])\n",
    "        else:\n",
    "            return Action(meal=0)\n",
    "\n",
    "    def create_scenario(self):\n",
    "        scenario = {'meal': {'time': [], 'amount': []}}\n",
    "\n",
    "        # Probability of taking each meal\n",
    "        # [breakfast, snack1, lunch, snack2, dinner, snack3]\n",
    "        prob = [0.95, 0.3, 0.95, 0.3, 0.95, 0.3]\n",
    "        time_lb = np.array([5, 9, 10, 14, 16, 20]) * 60\n",
    "        time_ub = np.array([9, 10, 14, 16, 20, 23]) * 60\n",
    "        time_mu = np.array([7, 9.5, 12, 15, 18, 21.5]) * 60\n",
    "        time_sigma = np.array([60, 30, 60, 30, 60, 30])\n",
    "        amount_mu = [45, 10, 70, 10, 80, 10]\n",
    "        amount_sigma = [10, 5, 10, 5, 10, 5]\n",
    "\n",
    "        for p, tlb, tub, tbar, tsd, mbar, msd in zip(prob, time_lb, time_ub,\n",
    "                                                     time_mu, time_sigma,\n",
    "                                                     amount_mu, amount_sigma):\n",
    "            if self.random_gen.rand() < p:\n",
    "                tmeal = np.round(\n",
    "                    truncnorm.rvs(a=(tlb - tbar) / tsd,\n",
    "                                  b=(tub - tbar) / tsd,\n",
    "                                  loc=tbar,\n",
    "                                  scale=tsd,\n",
    "                                  random_state=self.random_gen))\n",
    "                # Round to the nearest 5 minutes\n",
    "                tmeal_rounded = 5 * round(tmeal / 5)\n",
    "                scenario['meal']['time'].append(tmeal_rounded)\n",
    "                scenario['meal']['amount'].append(\n",
    "                    max(round(self.random_gen.normal(mbar, msd)), 0))\n",
    "\n",
    "        return scenario\n",
    "\n",
    "    def reset(self):\n",
    "        self.random_gen = np.random.RandomState(self.seed)\n",
    "        self.scenario = self.create_scenario()\n",
    "\n",
    "    @property\n",
    "    def seed(self):\n",
    "        return self._seed\n",
    "\n",
    "    @seed.setter\n",
    "    def seed(self, seed):\n",
    "        self._seed = seed\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "from datetime import time\n",
    "from datetime import timedelta\n",
    "import copy\n",
    "now = datetime.now()\n",
    "t0 = datetime.combine(now.date(), time(6, 0, 0, 0))\n",
    "t = copy.deepcopy(t0)\n",
    "sim_time = timedelta(days=2)\n",
    "\n",
    "scenario = RandomScenario(seed=1, start_time=t0)\n",
    "m = []\n",
    "T = []\n",
    "while t < t0 + sim_time:\n",
    "    action = scenario.get_action(t)\n",
    "    m.append(action.meal)\n",
    "    T.append(t)\n",
    "    t += timedelta(minutes=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "plt.plot(T, m)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(mdates.AutoDateLocator())\n",
    "ax.xaxis.set_minor_formatter(mdates.DateFormatter('%H:%M\\n'))\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('\\n%b %d'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 12:27:08,578 - __main__ - INFO - Time for meal!\n",
      "2023-12-21 12:27:11,016 - __main__ - INFO - Time for meal!\n"
     ]
    }
   ],
   "source": [
    "def custom_reward(BG_last_hour):\n",
    "    if BG_last_hour[-1] > 180:\n",
    "        return -1\n",
    "    elif BG_last_hour[-1] < 70:\n",
    "        return -2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "# register(\n",
    "#     id='simglucose-adolescent1-v0',\n",
    "#     entry_point='simglucose.envs:T1DSimEnv',\n",
    "#     kwargs={'patient_name': 'adolescent#001',\n",
    "#             'reward_fun': custom_reward,\n",
    "#             'scenario': scenario}\n",
    "# )\n",
    "\n",
    "env = gym.make(\"simglucose-adolescent2-v0\")\n",
    "\n",
    "reward = 1\n",
    "done = False\n",
    "\n",
    "observation = env.reset()\n",
    "# for t in range(200):\n",
    "now = datetime.now()\n",
    "\n",
    "t0 = datetime.combine(now.date(), time(6, 0, 0, 0))\n",
    "t = copy.deepcopy(t0)\n",
    "sim_time = timedelta(days=1)\n",
    "\n",
    "\n",
    "scenario = RandomScenario(seed=1, start_time=t0)\n",
    "m = []\n",
    "T = []\n",
    "while t < t0 + sim_time:\n",
    "    env.render(mode=\"human\")\n",
    "    action = scenario.get_action(t)\n",
    "    observation, reward, done, info = env.step(action.meal)\n",
    "    t += timedelta(minutes=5)\n",
    "\n",
    "    #TODO: align the time\n",
    "\n",
    "    #print(observation)\n",
    "    # print(\"Reward = {}\".format(reward))\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(t + 1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simulated CGM measurements have a sampling time of 5\n",
    "minutes, i.e. 288 CGM readings are available for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_time.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHO: meal carbohydrate intake,\n",
    "BG: blood glucose,\n",
    "CGM: continuous glucose monitoring,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simglucose.simulation.env import T1DSimEnv\n",
    "from simglucose.controller.basal_bolus_ctrller import BBController\n",
    "from simglucose.sensor.cgm import CGMSensor\n",
    "from simglucose.actuator.pump import InsulinPump\n",
    "from simglucose.patient.t1dpatient import T1DPatient\n",
    "from simglucose.simulation.scenario_gen import RandomScenario\n",
    "from simglucose.simulation.scenario import CustomScenario\n",
    "from simglucose.simulation.sim_engine import SimObj, sim, batch_sim\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "# specify start_time as the beginning of today\n",
    "now = datetime.now()\n",
    "start_time = datetime.combine(now.date(), datetime.min.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 12, 22, 0, 0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-21 00:00:00\n",
      "Process ID: 16476\n",
      "Simulation starts ...\n",
      "Simulation Completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------- Create Custom Scenario --------------\n",
    "# Create a simulation environment\n",
    "patient = T1DPatient.withName('adolescent#001')\n",
    "sensor = CGMSensor.withName('Dexcom', seed=1)\n",
    "pump = InsulinPump.withName('Insulet')\n",
    "# custom scenario is a list of tuples (time, meal_size)\n",
    "scen = [(7, 45), (12, 70), (16, 15), (18, 80), (23, 10)]\n",
    "scenario = CustomScenario(start_time=start_time, scenario=scen)\n",
    "#scenario = RandomScenario(start_time=start_time, seed=1)\n",
    "env = T1DSimEnv(patient, sensor, pump, scenario)\n",
    "print(env.time)\n",
    "# Create a controller\n",
    "controller = BBController()\n",
    "\n",
    "# Put them together to create a simulation object\n",
    "s2 = SimObj(env, controller, timedelta(days=1), animate=False, path='./results/')\n",
    "results2 = sim(s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BG</th>\n",
       "      <th>CGM</th>\n",
       "      <th>CHO</th>\n",
       "      <th>insulin</th>\n",
       "      <th>LBGI</th>\n",
       "      <th>HBGI</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-21 07:00:00</th>\n",
       "      <td>149.031646</td>\n",
       "      <td>144.881920</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.756812</td>\n",
       "      <td>2.756812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21 12:00:00</th>\n",
       "      <td>122.891316</td>\n",
       "      <td>135.460121</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270551</td>\n",
       "      <td>0.270551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21 16:00:00</th>\n",
       "      <td>109.598313</td>\n",
       "      <td>116.907385</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21 18:00:00</th>\n",
       "      <td>100.602854</td>\n",
       "      <td>99.276333</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.434217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21 23:00:00</th>\n",
       "      <td>96.539455</td>\n",
       "      <td>99.952845</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.812418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.812418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 00:00:00</th>\n",
       "      <td>93.059999</td>\n",
       "      <td>92.250490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.247680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.247680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             BG         CGM        CHO   insulin      LBGI  \\\n",
       "Time                                                                         \n",
       "2023-12-21 07:00:00  149.031646  144.881920  15.000000  0.013933  0.000000   \n",
       "2023-12-21 12:00:00  122.891316  135.460121  23.333333  0.013933  0.000000   \n",
       "2023-12-21 16:00:00  109.598313  116.907385   5.000000  0.013933  0.023985   \n",
       "2023-12-21 18:00:00  100.602854   99.276333  26.666667  0.013933  0.434217   \n",
       "2023-12-21 23:00:00   96.539455   99.952845   3.333333  0.013933  0.812418   \n",
       "2023-12-22 00:00:00   93.059999   92.250490        NaN       NaN  1.247680   \n",
       "\n",
       "                         HBGI      Risk  \n",
       "Time                                     \n",
       "2023-12-21 07:00:00  2.756812  2.756812  \n",
       "2023-12-21 12:00:00  0.270551  0.270551  \n",
       "2023-12-21 16:00:00  0.000000  0.023985  \n",
       "2023-12-21 18:00:00  0.000000  0.434217  \n",
       "2023-12-21 23:00:00  0.000000  0.812418  \n",
       "2023-12-22 00:00:00  0.000000  1.247680  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter for non-zero meals\n",
    "\n",
    "results2[results2['CHO'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I don't know how to use the variables that the model says or if we even have that information available.\n",
    "- For the moment the loop is only over one patient, not properly training yet\n",
    "- Implement reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_reward_function(BG_last_hour):\n",
    "    G = BG_last_hour[-1]\n",
    "    if G >= 70 and G <= 180:\n",
    "        return 0.5\n",
    "    if G > 180 and G <= 200:\n",
    "        return -0.9\n",
    "    if G > 200 and G <= 250:\n",
    "        return -1.2\n",
    "    if G > 250 and G <= 350:\n",
    "        return -1.5\n",
    "    if G > 30 and G < 70:\n",
    "        return -1.8\n",
    "    else:\n",
    "        return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Q-network\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        # Define your neural network architecture\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### select_action funtion\n",
    "\n",
    "1. The chosen action $a_t$ represents a percentage modulation $alpha_t$ of the mealtime insulin dose suggested by the standard therapy.\n",
    "2. The modulation factor $alpha_t$) is randomly chosen from a set of possible percentage modulations.\n",
    "3. The insulin amount suggested by the DDQN algorithm at time step $t$ is calculated using the formula: $BC_{ddqn}(t) = BC_s(t) + \\alpha_t \\cdot BC_s(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DDQ Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, input_size, output_size, gamma=0.99, learning_rate=0.001):\n",
    "        self.gamma = gamma\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Q-networks\n",
    "        self.q_network = QNetwork(input_size, output_size).to(self.device)\n",
    "        self.target_q_network = QNetwork(input_size, output_size).to(self.device)\n",
    "        self.target_q_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=learning_rate)\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        q_values = self.q_network(state_tensor)\n",
    "        action_index = q_values.argmax(1).item()\n",
    "        # Possible percentage modulations of the insulin dose\n",
    "        modulation_percentages = [25, 20, 10, 0, -10, -20, -25]\n",
    "        # now selecting the alpha percentage as a random choice from the modulation percentages\n",
    "        alpha_percentage = np.random.choice(modulation_percentages)\n",
    "        alpha_factor = 1 + (alpha_percentage / 100.0)  # Convert percentage to a factor\n",
    "\n",
    "        # Apply the modulation to the insulin dose suggested by standard therapy (BCs)\n",
    "        action_value = alpha_factor * action_index\n",
    "\n",
    "        return action_value\n",
    "\n",
    "    def update_q_network(self, state, action, reward, next_state, done):\n",
    "        state_tensor = torch.FloatTensor(state).to(self.device)\n",
    "        next_state_tensor = torch.FloatTensor(next_state).to(self.device)\n",
    "        action_tensor = torch.FloatTensor([action]).to(self.device)\n",
    "        reward_tensor = torch.FloatTensor([reward]).to(self.device)\n",
    "\n",
    "        # Q-value prediction for all actions\n",
    "        q_values = self.q_network(state_tensor)\n",
    "        \n",
    "        # Action_tensor and q_values shapes must match\n",
    "        action_tensor = action_tensor.expand_as(q_values)\n",
    "\n",
    "        # Q-value for the selected action\n",
    "        selected_q_value = torch.sum(q_values * action_tensor, dim=0, keepdim=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double Q-learning: Use the target network for action selection\n",
    "            next_q_values = self.target_q_network(next_state_tensor)\n",
    "            next_action_index = next_q_values.argmax(0, keepdim=True)\n",
    "            target_q_values = reward_tensor + self.gamma * next_q_values.gather(0, next_action_index) * (1 - done)\n",
    "\n",
    "        # Q-network loss\n",
    "        loss = nn.functional.mse_loss(selected_q_value, target_q_values)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_q_network(self):\n",
    "        # Update the target Q-network by copying the parameters from the current Q-network\n",
    "        self.target_q_network.load_state_dict(self.q_network.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "T1DSimEnv.__init__() got an unexpected keyword argument 'patient_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Simglucose environment setup\u001b[39;00m\n\u001b[0;32m      2\u001b[0m patient_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madolescent#010\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m env \u001b[38;5;241m=\u001b[39m T1DSimEnv(patient_name\u001b[38;5;241m=\u001b[39mpatient_name)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# DDQ Agent setup\u001b[39;00m\n\u001b[0;32m      6\u001b[0m state_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mlow)  \u001b[38;5;66;03m# Size of the state vector\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: T1DSimEnv.__init__() got an unexpected keyword argument 'patient_name'"
     ]
    }
   ],
   "source": [
    "# Simglucose environment setup\n",
    "patient_name = \"adolescent#010\"\n",
    "env = T1DSimEnv(patient_name=patient_name)\n",
    "\n",
    "# DDQ Agent setup\n",
    "state_size = len(env.observation_space.low)  # Size of the state vector\n",
    "action_size = len(env.action_space.low)  # Size of the action space\n",
    "agent = DQNAgent(input_size=state_size, output_size=action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Step(observation=Observation(CGM=149.80502445158902), reward=0.21085887551353366, done=False, info={'sample_time': 3.0, 'patient_name': 'adolescent#010', 'meal': 0.0, 'patient_state': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.69891197e+02,\n",
       "        1.65975038e+02,  6.30215227e+00, -1.33136366e-02,  1.08236338e+02,\n",
       "        1.08239971e+02,  3.58486790e+00,  8.84671285e+01,  7.75725653e+01,\n",
       "        2.72581852e+02]), 'time': datetime.datetime(2018, 1, 1, 15, 3), 'bg': 147.92056439066695, 'lbgi': 0.0, 'hbgi': 2.611626127620977, 'risk': 2.611626127620977})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "action = agent.select_action(state)\n",
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Total Reward: -97.87264021170513, GCM: 593.3493234822606\n",
      "Episode: 2, Total Reward: -97.30607057598033, GCM: 600.0\n",
      "Episode: 3, Total Reward: -96.29777539036654, GCM: 600.0\n",
      "Episode: 4, Total Reward: -92.08636765128593, GCM: 598.7223567284018\n",
      "Episode: 5, Total Reward: -94.87752929811349, GCM: 597.4718313861013\n",
      "Episode: 6, Total Reward: -95.176758063922, GCM: 595.0771923357318\n",
      "Episode: 7, Total Reward: -95.27126757951615, GCM: 600.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "capi_return is NULL\n",
      "Call-back cb_fcn_in___user__routines failed.\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/simglucose/patient/t1dpatient.py\", line 170, in model\n",
      "Fatal Python error: F2PySwapThreadLocalCallbackPtr: F2PySwapThreadLocalCallbackPtr: PyLong_AsVoidPtr failed\n",
      "Python runtime state: initialized\n",
      "    Kmt = params.Km0\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\", line 6201, in __getattr__\n",
      "    and self._info_axis._can_hold_identifiers_and_holds_name(name)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 5414, in _can_hold_identifiers_and_holds_name\n",
      "    is_object_dtype(self.dtype)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/common.py\", line 165, in is_object_dtype\n",
      "    return _is_dtype_type(arr_or_dtype, classes(np.object_))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 8, Total Reward: -95.31375314585537, GCM: 597.2737141061987\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_episodes = 1000\n",
    "TARGET_UPDATE_FREQUENCY = 10\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    first_iteration = True\n",
    "\n",
    "    while True:\n",
    "        action = agent.select_action(state)\n",
    "\n",
    "        # Step through the environment\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Update Q-network\n",
    "        agent.update_q_network(state, action, reward, next_state, done)\n",
    "\n",
    "        # Update target Q-network periodically\n",
    "        if episode % TARGET_UPDATE_FREQUENCY == 0:\n",
    "            agent.update_target_q_network()\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print(f\"Episode: {episode + 1}, Total Reward: {total_reward}, GCM: {next_state.CGM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "T1DSimEnv.__init__() missing 4 required positional arguments: 'patient', 'sensor', 'pump', and 'scenario'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming 'env' is your SimGlucose environment\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m T1DSimEnv()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Reset the environment to get the initial state\u001b[39;00m\n\u001b[0;32m      7\u001b[0m initial_observation \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "\u001b[1;31mTypeError\u001b[0m: T1DSimEnv.__init__() missing 4 required positional arguments: 'patient', 'sensor', 'pump', and 'scenario'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Assuming 'env' is your SimGlucose environment\n",
    "env = T1DSimEnv()\n",
    "\n",
    "# Reset the environment to get the initial state\n",
    "initial_observation = env.reset()\n",
    "\n",
    "# Take a step in the environment\n",
    "action = agent.select_action(initial_observation)\n",
    "next_observation, reward, done, info = env.step(action)\n",
    "\n",
    "# Access information from the 'info' dictionary\n",
    "cgm_measurement = next_observation.CGM\n",
    "blood_glucose = info['bg']\n",
    "current_time = info['time']\n",
    "meal_time = info['meal']\n",
    "\n",
    "# Print or use the information as needed\n",
    "print(f\"CGM Measurement: {cgm_measurement}\")\n",
    "print(f\"Blood Glucose: {blood_glucose}\")\n",
    "print(f\"Current Time: {current_time}\")\n",
    "print(f\"Meal Time: {meal_time}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
